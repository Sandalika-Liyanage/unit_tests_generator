import glob
import json
import os
from typing import List, Dict, Any, TypedDict, Optional
from dotenv import load_dotenv

# LangChain / LangGraph imports
from langgraph.graph import END, StateGraph

# Import agents
from code_analyzer_agent import code_analyser_node
from function_path_agent import function_path_node
from test_strategist_agent import test_strategist_node
from test_writer_agent import test_writer_node

load_dotenv()

# --- State Definition ---
class TestGenerationState(TypedDict):
    file_path: str
    source_code: Optional[str] 
    code_map: Dict[str, Any]
    execution_paths: Dict[str, Any]
    test_scenarios: List[Dict[str, Any]]
    generated_tests: List[str]
    current_scenario_index: int

# --- Conditional Logic ---
def should_continue_writing(state: TestGenerationState) -> str:
    """Determines whether to continue writing tests"""
    current_index = state.get("current_scenario_index", 0)
    total_scenarios = len(state.get("test_scenarios", []))
    
    if current_index < total_scenarios:
        return "continue"
    else:
        print("All tests generated!")
        return "end"

# --- Graph Construction ---
def build_workflow():
    """Build and compile the test generation workflow."""
    workflow = StateGraph(TestGenerationState)

    # Add nodes (agents)
    workflow.add_node("code_analyser", code_analyser_node)
    workflow.add_node("function_path", function_path_node) 
    workflow.add_node("test_strategist", test_strategist_node)
    workflow.add_node("test_writer", test_writer_node)

    # Set entry point
    workflow.set_entry_point("code_analyser")

    # Add edges (flow)
    workflow.add_edge("code_analyser", "function_path")
    workflow.add_edge("function_path", "test_strategist") 
    workflow.add_conditional_edges(
        "test_strategist",
        should_continue_writing,
        {"continue": "test_writer", "end": END}
    )
    workflow.add_conditional_edges(
        "test_writer", 
        should_continue_writing,
        {"continue": "test_writer", "end": END}
    )

    # Compile the workflow
    return workflow.compile()

# --- Main Execution Logic ---
if __name__ == "__main__":
    # Configuration
    repo_path = "app"  # Path relative to the script's location
    output_dir = "generated_tests"
    
    # Validate API key
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    if not OPENAI_API_KEY:
        print("Please set your OpenAI API key!")
        print("Either set the OPENAI_API_KEY environment variable or update the .env file.")
        exit(1)

    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # Find all Python files
    source_files = glob.glob(f"{repo_path}/**/*.py", recursive=True)
    
    # Filter out test files and __pycache__
    source_files = [f for f in source_files if not f.endswith('test.py') 
                and 'test_' not in os.path.basename(f)
                and '__pycache__' not in f
                and '__init__.py' not in f]  # Skip __init__.py files

    if not source_files:
        print(f"No Python files found in {repo_path}. Please check the path.")
        exit(1)
    
    print(f"Found {len(source_files)} Python files to test.\n")
    
    # Build the workflow
    app = build_workflow()
    
    # Process each file
    for i, file_path in enumerate(source_files, 1):
        print(f"\n{'='*60}")
        print(f"Processing file {i}/{len(source_files)}: {file_path}")
        print(f"{'='*60}")
        
        # Initialize state
        inputs = {
            "file_path": file_path,
            "source_code": None,
            "code_map": {},
            "execution_paths": {},
            "test_scenarios": [],
            "generated_tests": [],
            "current_scenario_index": 0
        }
        
        try:
            # Run the workflow
            result = app.invoke(inputs)
            
            # Save generated tests
            if result.get("generated_tests"):
                base_name = os.path.basename(file_path).replace('.py', '')
                output_file_path = os.path.join(output_dir, f"test_{base_name}.py")
                
                with open(output_file_path, 'w', encoding='utf-8') as f:
                    f.write("# Auto-generated tests using AI-powered multi-agent analysis\n")
                    f.write(f"# Source file: {file_path}\n")
                    f.write("# Generated by LangGraph Test Generator\n\n")
                    f.write("import pytest\n")
                    f.write("from unittest.mock import Mock, patch\n\n")
                    
                    for j, test_code in enumerate(result["generated_tests"], 1):
                        f.write(f"# Test {j}\n")
                        f.write(test_code)
                        f.write("\n\n")
                
                print(f"Generated {len(result['generated_tests'])} tests saved to {output_file_path}")
            else:
                print(f"No tests generated for {file_path}")
                
        except Exception as e:
            print(f"Error processing {file_path}: {e}")
            continue
    
    print(f"\nTest generation completed! Check the '{output_dir}' directory for results.")